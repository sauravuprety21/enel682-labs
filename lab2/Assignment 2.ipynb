{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (40 marks total)\n",
    "### Due: February 16 at 11:59pm\n",
    "\n",
    "### Name: Saurav Uprety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (20 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type <class 'pandas.core.frame.DataFrame'> and size (4600, 57)\n",
      "y is of type <class 'pandas.core.series.Series'> and size (4600,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "X, y = load_spam()\n",
    "print(f\"X is of type {type(X)} and size {X.shape}\")\n",
    "print(f\"y is of type {type(y)} and size {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (2 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3006203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_#                   0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary (1 mark)\n",
    "\n",
    "# No column has null-values, therefore no missing data in X\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "891de3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No null-values, therefore no missing data in y\n",
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.21               0.28           0.50           0.0   \n",
       "1            0.06               0.00           0.71           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.14            0.28              0.21                0.07   \n",
       "1           1.23            0.19              0.19                0.12   \n",
       "2           0.63            0.00              0.31                0.63   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           1.85            0.00              0.00                1.85   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0             0.00            0.94  ...                   0.0         0.00   \n",
       "1             0.64            0.25  ...                   0.0         0.01   \n",
       "2             0.31            0.63  ...                   0.0         0.00   \n",
       "3             0.31            0.63  ...                   0.0         0.00   \n",
       "4             0.00            0.00  ...                   0.0         0.00   \n",
       "\n",
       "   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0        0.132          0.0        0.372        0.180        0.048   \n",
       "1        0.143          0.0        0.276        0.184        0.010   \n",
       "2        0.137          0.0        0.137        0.000        0.000   \n",
       "3        0.135          0.0        0.135        0.000        0.000   \n",
       "4        0.223          0.0        0.000        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       5.114                         101   \n",
       "1                       9.821                         485   \n",
       "2                       3.537                          40   \n",
       "3                       3.537                          40   \n",
       "4                       3.000                          15   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                      1028  \n",
       "1                      2259  \n",
       "2                       191  \n",
       "3                       191  \n",
       "4                        54  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "754b008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4600 non-null   float64\n",
      " 1   word_freq_address           4600 non-null   float64\n",
      " 2   word_freq_all               4600 non-null   float64\n",
      " 3   word_freq_3d                4600 non-null   float64\n",
      " 4   word_freq_our               4600 non-null   float64\n",
      " 5   word_freq_over              4600 non-null   float64\n",
      " 6   word_freq_remove            4600 non-null   float64\n",
      " 7   word_freq_internet          4600 non-null   float64\n",
      " 8   word_freq_order             4600 non-null   float64\n",
      " 9   word_freq_mail              4600 non-null   float64\n",
      " 10  word_freq_receive           4600 non-null   float64\n",
      " 11  word_freq_will              4600 non-null   float64\n",
      " 12  word_freq_people            4600 non-null   float64\n",
      " 13  word_freq_report            4600 non-null   float64\n",
      " 14  word_freq_addresses         4600 non-null   float64\n",
      " 15  word_freq_free              4600 non-null   float64\n",
      " 16  word_freq_business          4600 non-null   float64\n",
      " 17  word_freq_email             4600 non-null   float64\n",
      " 18  word_freq_you               4600 non-null   float64\n",
      " 19  word_freq_credit            4600 non-null   float64\n",
      " 20  word_freq_your              4600 non-null   float64\n",
      " 21  word_freq_font              4600 non-null   float64\n",
      " 22  word_freq_000               4600 non-null   float64\n",
      " 23  word_freq_money             4600 non-null   float64\n",
      " 24  word_freq_hp                4600 non-null   float64\n",
      " 25  word_freq_hpl               4600 non-null   float64\n",
      " 26  word_freq_george            4600 non-null   float64\n",
      " 27  word_freq_650               4600 non-null   float64\n",
      " 28  word_freq_lab               4600 non-null   float64\n",
      " 29  word_freq_labs              4600 non-null   float64\n",
      " 30  word_freq_telnet            4600 non-null   float64\n",
      " 31  word_freq_857               4600 non-null   float64\n",
      " 32  word_freq_data              4600 non-null   float64\n",
      " 33  word_freq_415               4600 non-null   float64\n",
      " 34  word_freq_85                4600 non-null   float64\n",
      " 35  word_freq_technology        4600 non-null   float64\n",
      " 36  word_freq_1999              4600 non-null   float64\n",
      " 37  word_freq_parts             4600 non-null   float64\n",
      " 38  word_freq_pm                4600 non-null   float64\n",
      " 39  word_freq_direct            4600 non-null   float64\n",
      " 40  word_freq_cs                4600 non-null   float64\n",
      " 41  word_freq_meeting           4600 non-null   float64\n",
      " 42  word_freq_original          4600 non-null   float64\n",
      " 43  word_freq_project           4600 non-null   float64\n",
      " 44  word_freq_re                4600 non-null   float64\n",
      " 45  word_freq_edu               4600 non-null   float64\n",
      " 46  word_freq_table             4600 non-null   float64\n",
      " 47  word_freq_conference        4600 non-null   float64\n",
      " 48  char_freq_;                 4600 non-null   float64\n",
      " 49  char_freq_(                 4600 non-null   float64\n",
      " 50  char_freq_[                 4600 non-null   float64\n",
      " 51  char_freq_!                 4600 non-null   float64\n",
      " 52  char_freq_$                 4600 non-null   float64\n",
      " 53  char_freq_#                 4600 non-null   float64\n",
      " 54  capital_run_length_average  4600 non-null   float64\n",
      " 55  capital_run_length_longest  4600 non-null   int64  \n",
      " 56  capital_run_length_total    4600 non-null   int64  \n",
      "dtypes: float64(55), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c10c91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: is_spam, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b63734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Series name: is_spam\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "4600 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 36.1 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **3%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small (1 mark)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_small, X_test, y_small, y_test = train_test_split(X, y, train_size=0.03, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5.1: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "results = pd.DataFrame(columns=['Data Size', 'Training Accuracy', 'Test Accuracy'])\n",
    "\n",
    "for i, (X_, y_ )in enumerate(zip([X, X.iloc[:,:2], X_small], [y, y, y_small])):\n",
    "    \n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, random_state=0)\n",
    "    logreg_ = LogisticRegression(max_iter=2000, random_state=0).fit(X_train_, y_train_)\n",
    "\n",
    "    results.loc[i] = {'Data Size': X_train_.shape,\n",
    "                  'Training Accuracy': logreg_.score(X_train_, y_train_),\n",
    "                  'Test Accuracy': logreg_.score(X_test_, y_test_)}\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a160b9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3450, 57)</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.936522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3450, 2)</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(103, 57)</td>\n",
       "      <td>0.961165</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Size  Training Accuracy  Test Accuracy\n",
       "0  (3450, 57)           0.928696       0.936522\n",
       "1   (3450, 2)           0.608406       0.613043\n",
       "2   (103, 57)           0.961165       0.885714"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a54f",
   "metadata": {},
   "source": [
    "### Step 5.2: Visualize Classification Errors (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022252f",
   "metadata": {},
   "source": [
    "In this section, print the confusion matrix and the classification report to investigate the number of false positives vs. false negatives. Use the full dataset for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81931e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Retrieve target vector and predicted values for validation set using full dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "logreg = LogisticRegression(random_state=0, max_iter=2000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4cb30f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, logreg.predict(X_test))\n",
    "\n",
    "sns.heatmap(conf, xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'], annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')\n",
    "print()\n",
    "# HINT: To remove scientific notation from a heatmap, set the parameter fmt='d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bfb397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Spam       0.94      0.95      0.95       692\n",
      "        Spam       0.92      0.91      0.92       458\n",
      "\n",
      "    accuracy                           0.94      1150\n",
      "   macro avg       0.93      0.93      0.93      1150\n",
      "weighted avg       0.94      0.94      0.94      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, logreg.predict(X_test),\n",
    "                            target_names=['Not Spam', 'Spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "1. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "1. Based on your answer to question 2, would you want to maximize precision or recall? How would you do this?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f28eb5",
   "metadata": {},
   "source": [
    "1. In this question, the amount of data used is varied in two way: first of all the sample size is varied by comparing model based on the entire data set (X, y) with the model based on downsampled dataset (X_small, y_small); and secondly, the feature space is varied by comparing the model based on all features with the model based on only two features or columns. <br><br>\n",
    "With regards to the first point, using a smaller data size to train the model leads to overfitting, which is demonstrated by the large difference in traning versus validation score (0.9903 vs. 0.8857) for the model based on the (X_small, y_small) dataset. This correspoends to the left-hand side of the *Learning Curve* where, the training set size is small, leading to a high-variance model. Once, the training size is sufficiently large, the Learning Cruve progresses to the right hand-side where the Validation and Training scores converge. This is the case with model based on the full dataset (X,y), which has comparable training versus validation scores (0.9287, 0.9365).<br><br>\n",
    "For the second point, with the feature space diminished, there might not be enough information to make reliable predictions. This is an example of a simplistic model, or under fitting. The trainining versus validation scores for when only two columns are used are 0.6084 and 0.6130 respectively. The low scores, indicate that the model is not sophisticated enough to make accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa78e3",
   "metadata": {},
   "source": [
    "2. Since the goal of the model is to predict spam emails, the positive class is *is spam*, while the negative class is *not spam*. The false positives represent *not spam* emails which were incorrectly predicted to be *spam*. Whereas, false negatives are *spam* emails which were incorrectly predicted to be *not spam*. In this case, false positives are worse because important, *not spam* emails maybe predicted as spam, and consequently, filtered out. Whereas, a few spam emails passing through the filter is not as big of a deal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c9bbb",
   "metadata": {},
   "source": [
    "3. I would aim to maximize precision, as the goal of precision is to limit the number of false positives. Trade offs between precision and recall can be made by changing the threshold of the decision function. The default value of the threshold is 0, lowering the threshold would mean that more points are classifed as negatives or not spam. This would also lower the number of false positives, and hence, increase precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC* <br>\n",
    "I wrote the code myself, I have prior experience in Pandas and Python. I did utilize Pandas and Sklearn python documentation at many points to recall or better understand functions. To learn the background on the logistic classification, I used the *Introduction to Machine Learning with Python* text book Chapter 5 and the examples provided in D2L. I completed the steps in order, however, for steps 3-5 I was a bit confused by the instructions, as I was not sure how to do the test train split given the data splits already perscribed in the instructions. I finally assumed that each of the described datasets had to be further split into test train and went with this assumption. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 2: Regression (15 marks)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is of type <class 'pandas.core.frame.DataFrame'> and size (1030, 8)\n",
      "y is of type <class 'pandas.core.series.Series'> and size (1030,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library (0.5 marks)\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# TO DO: Print size and type of X and y (0.5 marks)\n",
    "X, y = load_concrete()\n",
    "\n",
    "print(f\"X is of type {type(X)} and size {X.shape}\")\n",
    "print(f\"y is of type {type(y)} and size {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1 mark)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06fc9c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement    0\n",
       "slag      0\n",
       "ash       0\n",
       "water     0\n",
       "splast    0\n",
       "coarse    0\n",
       "fine      0\n",
       "age       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "# No column has null-values, therefore no missing data in X\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36239ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No null-values, therefore no missing data in y\n",
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ff0a9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>splast</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  ash  water  splast  coarse   fine  age\n",
       "0   540.0    0.0  0.0  162.0     2.5  1040.0  676.0   28\n",
       "1   540.0    0.0  0.0  162.0     2.5  1055.0  676.0   28\n",
       "2   332.5  142.5  0.0  228.0     0.0   932.0  594.0  270\n",
       "3   332.5  142.5  0.0  228.0     0.0   932.0  594.0  365\n",
       "4   198.6  132.4  0.0  192.0     0.0   978.4  825.5  360"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10774fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cement  1030 non-null   float64\n",
      " 1   slag    1030 non-null   float64\n",
      " 2   ash     1030 non-null   float64\n",
      " 3   water   1030 non-null   float64\n",
      " 4   splast  1030 non-null   float64\n",
      " 5   coarse  1030 non-null   float64\n",
      " 6   fine    1030 non-null   float64\n",
      " 7   age     1030 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 64.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90b0cf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.986111\n",
       "1    61.887366\n",
       "2    40.269535\n",
       "3    41.052780\n",
       "4    44.296075\n",
       "Name: strength, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9909c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Series name: strength\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "1030 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 8.2 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (2 marks)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12185954  0.11060501  0.0953879  -0.1419938   0.31529263  0.02485841\n",
      "  0.02486899  0.11270849] -36.54109819991134\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (2 marks)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training R2 score is: 0.6108229424520555\n",
      "The testing R2 score is: 0.6234144623633329\n",
      "The training MSE score is: 111.35843861132467\n",
      "The testing MSE score is: 95.90413603680643\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "print(f\"The training R2 score is: {lr.score(X_train, y_train)}\")\n",
    "print(f\"The testing R2 score is: {lr.score(X_test, y_test)}\")\n",
    "\n",
    "print(f\"The training MSE score is: {mse(lr.predict(X_train), y_train)}\")\n",
    "print(f\"The testing MSE score is: {mse(lr.predict(X_test), y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59ae0f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Accuracy  Validation Accuracy\n",
       "R2            0.610823             0.623414\n",
       "MSE         111.358439            95.904136"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'], index=['R2', 'MSE'],\n",
    "                    data=[[lr.score(X_train, y_train), lr.score(X_test, y_test)],\n",
    "                          [mse(lr.predict(X_train), y_train), mse(lr.predict(X_test), y_test)]])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "1. Could we tell if this model was a good fit by using just the mean squared error? Why or why not?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c1b7f",
   "metadata": {},
   "source": [
    "1. Linear Model did not produce a good result for this dataset. The training and validation Accuracies (0.6108, 0.6234) are both low indicating, an underfitting model or high-bias. Since, the two accuracies are close this means that the training size is not a limiting factor, and the model is performing on the right side of the Learning curve. To improve the performance, a more sophisticated model must be used. <br><br>\n",
    "2. The Mean Squared Error (MSE) alone does not provide enough information about the model fit. I think this is because MSE is a quantity with dimensions, hence, more context regarding the physics and engineering practice surrounding the problem is required to make model judgement based off MSE. For example in analyzaing positioning algorithims or models, the MSE is valueable, as the dimensions of length e.g., meter or centimeter positioning performance is intutive to understand and appreciate. However, when removed from the domain, the dimensionless performance indicator such as R2 is more valuable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d6120",
   "metadata": {},
   "source": [
    "As with the previous part, I wrote the code myself. I utilized Pandas and Sklearn documentation for some clarification, and utilized the *Introduction to Machine Learning with Python* textbook along with the course notes and examples for understanding linear regression better. I completed the steps in the order perscribed, and did not have challenges with this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abb8e5",
   "metadata": {},
   "source": [
    "One interesting pattern is that even though validation score should generally be lower than training score, sometimes this is not the case. For example, in Part 1, for the full dataset based and two column based classification, the validation scores are higher (0.9365 and 0.61305 compared to 0.9287 and 0.6084). Same for Part 2, with validation score of 0.6234 compared to training score of 0.6108. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513105",
   "metadata": {},
   "source": [
    "I liked that the questions utlized real datasets, and although the processes of applying ML is repetitive, the use of a new dataset for a new challenge, made it challenging and kept it exciting. <br><br>\n",
    "I think assignments with less instructions and more of a project like structure would be even more enjoyable, as we will have to problem solve and research extensively. <br><br>\n",
    "The only confusing part was the wording the the Part A, about training the three different logistic regression models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
